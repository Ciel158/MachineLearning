{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4dd94f-4c42-492e-a68b-75e18e859298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 교차검증(Cross-Validation)\n",
    "\n",
    "\n",
    "#일반화 성능을 평가하기 위해 훈련 세트와 테스트 세트로 나누어 한번 평가하는 것보다 안정적이고 뛰어난 통계적 평가 방법\n",
    "#데이터를 여러 번 반복해서 나누고 여러 모델을 학습\n",
    "\n",
    "#가장 일반적인 교차 검증 방법은 k-겹 교차검증(k-fole cross-validation)으로 k에 보통 5 또는 10을 사용\n",
    "#데이터를 먼저 k개의 fold(부분집합)으로 나눔\n",
    "#각각의 폴드를 테스트 세트로 하고 나머지를 훈련 세트로 하여 5번 평가를 반복\n",
    "#이렇게 하면 k개의 정확도를 얻을 수 있음\n",
    "#다만, 시간이 더 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccc3607-7eab-4007-9e5a-9ae71c4a1670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris data shape: (150, 4)\n",
      "Iris labels: {0, 1, 2}\n",
      "Cross-validation scores: [0.98 0.96 0.98]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score #folder\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3) #값이 소수점 이하 둘째자리까지만 나오도록 세팅\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print(\"Iris data shape: {}\".format(iris.data.shape))\n",
    "print(\"Iris labels: {}\".format(set(iris.target)))\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "# 평가할 모형, 독립변수, 종속변수, k(fold의 수)의 순서로 매개변수를 설정\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=3) #cv >> data folder의 수\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3cb108-6a77-49c5-a7e0-e4f222fde228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.967 1.    0.933 0.967 1.   ]\n"
     ]
    }
   ],
   "source": [
    "# k를 5개로 변경해서 평가를 수행\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b99c69-ce99-47ea-9f2c-13a44b11bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# 얻어진 k개의 정확도에 대해 평균을 계산\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5697a-59d2-4cd2-a0b1-02f836576c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#계층별 k-겹 교차 검증(Stratified K-Fold cross-validation)\n",
    "#데이터셋을 순서대로 k개의 폴더로 하는 것은 문제 가능성이 있음\n",
    "#예를 들어 극단적인 경우, 종속변수가 [0,0,0, 1, 1, 1, 2, 2, 2, ]의 형태로 되어 있다면 세 개의 폴더로 했을 때, 학습이 전혀 되지 않는 결과가 발생\n",
    "#이를 해결하기 위해서는 먼저 random shuffling을 할 수 있고,\n",
    "#둘째로 계층별 k-겹 교차검증을 할 수 있음\n",
    "#계층별 k-겹 교차검증은 각 폴드 안의 클래스 비율이 전체 데이터셋의 클래스 비율과 같도록 데이터를 나눔\n",
    "#분류기에 대해서는 계층별 k-겹 교차검증을 사용하는 것이 보다 안정적임\n",
    "#클래스간의 inbalanced가 강한 경우 해결(셔플만 잘해줘도 해결이 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b74b3ad-9411-4f70-b401-7e516844dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본적인 사용방법\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480cc965-7682-4017-b745-69c82ad3c7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[1.    1.    0.867 0.933 0.833]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold))) #이렇게만 쓸거면 cv=5써도 ㄱㅊ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c659ae-bfa6-4ea9-8998-db6701ed201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e5350ae-8195-44b1-94f2-463ad31ce9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.98 0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 셔플링 등의 조절이 가능\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a991cc-9113-4385-b25f-ca26cea6d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cv iterations:  150\n",
      "Mean accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "#LOOCV(Leave-one-out cross-validation)\n",
    "#폴드 하나에 샘플 하나만 있는 k-겹 교차 검증. 시간이 매우 오래 걸리는 단점이 있음\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
    "print(\"Number of cv iterations: \", len(scores))\n",
    "print(\"Mean accuracy: {:.2f}\".format(scores.mean()))\n",
    "#print(len(iris.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cfd7973-3113-4ee9-afed-2267eeddb334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.987 0.973 0.96  0.96  0.92  0.96  0.987 0.947 0.973 0.973]\n"
     ]
    }
   ],
   "source": [
    "#임의분할 교차검증(Shuffle-split cross-validation) 스토캐스틱\n",
    "#중복을 허용하는 샘플링, 매번 훈련-테스트 집합을 만들 때마다 전체 데이터셋에서 랜덤하게 샘플링을 수행.\n",
    "\n",
    "#샘플이 10개일 때, 훈련 세트는 5개, 테스트 세트는 2개로 하여 4번의 세트를 만듦 \n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10) #.5 .2 >얼마나 넣을까\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ee6e1-53be-4dd7-ba0c-82578d5a7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#매개변수 튜닝을 통한 일반화 성능의 개선방법\n",
    "#그리드 서치: 매개변수들의 모든 가능한 조합에 대해 테스트를 시도하여 결과가 가장 좋은 매개변수 조합을 찾는 것\n",
    "#log scale > *10단위로 늘려보는 거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664637b4-1b05-4874-b34a-005fe0b1736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 112   size of test set: 38\n",
      "Best score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# naive grid search implementation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "                                                    random_state=0)\n",
    "print(\"Size of training set: {}   size of test set: {}\".format(\n",
    "      X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "scores = []\n",
    "parameters= []\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set\n",
    "        score = svm.score(X_test, y_test)\n",
    "        #train.set으로 학습>test.set일반화ㄱㅊ은지 확인\n",
    "        #이 코드는 답지 확인 함 >튜닝할 때 사용X \n",
    "        # >> train셋을 다시 나눠서 체크함. Train, Validation, Test 셋트로 나눔. \n",
    "        parameters.append((gamma,C))\n",
    "        scores.append(score)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f974404-38ce-4467-bbfd-fe6d7c677c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23684210526315788, 0.23684210526315788, 0.23684210526315788, 0.5789473684210527, 0.9210526315789473, 0.9736842105263158, 0.23684210526315788, 0.23684210526315788, 0.5789473684210527, 0.9210526315789473, 0.9736842105263158, 0.9736842105263158, 0.23684210526315788, 0.23684210526315788, 0.9210526315789473, 0.9736842105263158, 0.9736842105263158, 0.9473684210526315, 0.23684210526315788, 0.23684210526315788, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.23684210526315788, 0.23684210526315788, 0.2894736842105263, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.23684210526315788, 0.23684210526315788, 0.23684210526315788, 0.34210526315789475, 0.4473684210526316, 0.4473684210526316]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791549a4-12ef-44ee-97e9-8ae3a49e0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for in zip():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57fc587d-1170-4cc4-a780-7eb26d6a1188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 84   size of validation set: 28   size of test set: 38\n",
      "\n",
      "Best score on validation set: 0.96\n",
      "Best parameters:  {'C': 10, 'gamma': 0.001}\n",
      "Test set score with best parameters: 0.92\n"
     ]
    }
   ],
   "source": [
    "#위 코드는 train.set으로 학습>test.set일반화ㄱㅊ은지 확인\n",
    "#SO, 이 모형은 답지 확인 함 >튜닝할 때 사용X \n",
    "# >> train셋을 다시 나눠서 체크함. Train, Validation, Test 셋트로 나눔. \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "# split train+validation set into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trainval, y_trainval, random_state=1)\n",
    "print(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the validation set\n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "# rebuild a model on the combined training and validation set,\n",
    "# and evaluate it on the test set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "\n",
    "# 테스트 스코어가 검증 세트가 없을 때와는 확연히 다른 것을 볼 수 있음\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e89191-6156-4df1-9c57-34527bf62c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
